Overview:

Real-time Sign Language Detection is a deep learning-based system that translates sign language gestures into text. The project leverages a Convolutional Neural Network (CNN) model trained on labeled gesture data to assist vocally impaired individuals in communication. The system processes video input in real-time using OpenCV and TensorFlow.


Features:

-Real-time Gesture Recognition: Detects and translates sign language gestures into text instantly.

-Deep Learning Model: Utilizes a CNN trained on labeled gesture datasets for accurate predictions.

-Computer Vision Integration: Uses OpenCV for video processing and real-time detection.

-User-Friendly Interface: Provides an interactive environment to facilitate sign language communication.


Technologies Used:

-Python

-TensorFlow

-OpenCV

-LabelImg (for annotating images)

-Jupyter Notebook
